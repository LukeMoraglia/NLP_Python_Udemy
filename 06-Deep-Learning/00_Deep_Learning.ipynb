{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1dfdb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd87ea49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukem\\anaconda3\\envs\\nlp_course\\lib\\site-packages\\sklearn\\utils\\validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d491e25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed458199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3af950a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8d9f799",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68ef74bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddd92216",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y) # one hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7a20e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4960bdb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a313b20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e90dadbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff8951bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94543264",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "587d3883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "731fcd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_s = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4401996e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_s = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a9dd3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7511f6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\lukem\\anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim = 4, activation='relu'))\n",
    "model.add(Dense(8, input_dim = 4, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4dc1743a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 139\n",
      "Trainable params: 139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03757c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\lukem\\anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/150\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1200 - accuracy: 0.3100\n",
      "Epoch 2/150\n",
      "100/100 [==============================] - 0s 50us/step - loss: 1.1111 - accuracy: 0.3900\n",
      "Epoch 3/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 1.1035 - accuracy: 0.3600\n",
      "Epoch 4/150\n",
      "100/100 [==============================] - 0s 60us/step - loss: 1.0954 - accuracy: 0.3600\n",
      "Epoch 5/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 1.0875 - accuracy: 0.3600\n",
      "Epoch 6/150\n",
      "100/100 [==============================] - 0s 60us/step - loss: 1.0800 - accuracy: 0.3600\n",
      "Epoch 7/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 1.0725 - accuracy: 0.3700\n",
      "Epoch 8/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 1.0645 - accuracy: 0.3800\n",
      "Epoch 9/150\n",
      "100/100 [==============================] - 0s 60us/step - loss: 1.0568 - accuracy: 0.3900\n",
      "Epoch 10/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 1.0489 - accuracy: 0.4100\n",
      "Epoch 11/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 1.0404 - accuracy: 0.4500\n",
      "Epoch 12/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 1.0323 - accuracy: 0.4900\n",
      "Epoch 13/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 1.0242 - accuracy: 0.5300\n",
      "Epoch 14/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 1.0164 - accuracy: 0.5800\n",
      "Epoch 15/150\n",
      "100/100 [==============================] - 0s 60us/step - loss: 1.0087 - accuracy: 0.5800\n",
      "Epoch 16/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 1.0011 - accuracy: 0.6000\n",
      "Epoch 17/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.9935 - accuracy: 0.6000\n",
      "Epoch 18/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.9857 - accuracy: 0.6200\n",
      "Epoch 19/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.9780 - accuracy: 0.6100\n",
      "Epoch 20/150\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.9705 - accuracy: 0.6000\n",
      "Epoch 21/150\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.9636 - accuracy: 0.6200\n",
      "Epoch 22/150\n",
      "100/100 [==============================] - 0s 95us/step - loss: 0.9562 - accuracy: 0.6100\n",
      "Epoch 23/150\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.9492 - accuracy: 0.5700\n",
      "Epoch 24/150\n",
      "100/100 [==============================] - 0s 100us/step - loss: 0.9415 - accuracy: 0.5800\n",
      "Epoch 25/150\n",
      "100/100 [==============================] - 0s 140us/step - loss: 0.9345 - accuracy: 0.5600\n",
      "Epoch 26/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.9271 - accuracy: 0.5400\n",
      "Epoch 27/150\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.9193 - accuracy: 0.6200\n",
      "Epoch 28/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.9115 - accuracy: 0.6400\n",
      "Epoch 29/150\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.9031 - accuracy: 0.6700\n",
      "Epoch 30/150\n",
      "100/100 [==============================] - 0s 95us/step - loss: 0.8946 - accuracy: 0.6900\n",
      "Epoch 31/150\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.8860 - accuracy: 0.7000\n",
      "Epoch 32/150\n",
      "100/100 [==============================] - 0s 100us/step - loss: 0.8770 - accuracy: 0.6800\n",
      "Epoch 33/150\n",
      "100/100 [==============================] - 0s 100us/step - loss: 0.8685 - accuracy: 0.6800\n",
      "Epoch 34/150\n",
      "100/100 [==============================] - 0s 100us/step - loss: 0.8596 - accuracy: 0.7000\n",
      "Epoch 35/150\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.8506 - accuracy: 0.7000\n",
      "Epoch 36/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.8413 - accuracy: 0.7100\n",
      "Epoch 37/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.8318 - accuracy: 0.7100\n",
      "Epoch 38/150\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.8225 - accuracy: 0.7000\n",
      "Epoch 39/150\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.8121 - accuracy: 0.6900\n",
      "Epoch 40/150\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.8023 - accuracy: 0.6800\n",
      "Epoch 41/150\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.7925 - accuracy: 0.6800\n",
      "Epoch 42/150\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.7827 - accuracy: 0.6800\n",
      "Epoch 43/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.7729 - accuracy: 0.6800\n",
      "Epoch 44/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.7636 - accuracy: 0.6800\n",
      "Epoch 45/150\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.7536 - accuracy: 0.6800\n",
      "Epoch 46/150\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.7439 - accuracy: 0.6800\n",
      "Epoch 47/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.7344 - accuracy: 0.6900\n",
      "Epoch 48/150\n",
      "100/100 [==============================] - 0s 85us/step - loss: 0.7237 - accuracy: 0.7100\n",
      "Epoch 49/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.7133 - accuracy: 0.7300\n",
      "Epoch 50/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.7023 - accuracy: 0.7400\n",
      "Epoch 51/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.6911 - accuracy: 0.7400\n",
      "Epoch 52/150\n",
      "100/100 [==============================] - 0s 71us/step - loss: 0.6810 - accuracy: 0.7700\n",
      "Epoch 53/150\n",
      "100/100 [==============================] - 0s 105us/step - loss: 0.6724 - accuracy: 0.7900\n",
      "Epoch 54/150\n",
      "100/100 [==============================] - 0s 100us/step - loss: 0.6645 - accuracy: 0.8400\n",
      "Epoch 55/150\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.6558 - accuracy: 0.8400\n",
      "Epoch 56/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.6465 - accuracy: 0.8400\n",
      "Epoch 57/150\n",
      "100/100 [==============================] - 0s 75us/step - loss: 0.6375 - accuracy: 0.8400\n",
      "Epoch 58/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.6290 - accuracy: 0.8500\n",
      "Epoch 59/150\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.6204 - accuracy: 0.8700\n",
      "Epoch 60/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.6126 - accuracy: 0.8800\n",
      "Epoch 61/150\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.6048 - accuracy: 0.8800\n",
      "Epoch 62/150\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.5970 - accuracy: 0.8900\n",
      "Epoch 63/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.5903 - accuracy: 0.8800\n",
      "Epoch 64/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.5827 - accuracy: 0.8800\n",
      "Epoch 65/150\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.5757 - accuracy: 0.8900\n",
      "Epoch 66/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.5692 - accuracy: 0.9100\n",
      "Epoch 67/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.5633 - accuracy: 0.9200\n",
      "Epoch 68/150\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.5566 - accuracy: 0.9300\n",
      "Epoch 69/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.5503 - accuracy: 0.9300\n",
      "Epoch 70/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.5442 - accuracy: 0.9300\n",
      "Epoch 71/150\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.5381 - accuracy: 0.9400\n",
      "Epoch 72/150\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.5321 - accuracy: 0.9400\n",
      "Epoch 73/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.5263 - accuracy: 0.9300\n",
      "Epoch 74/150\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.5206 - accuracy: 0.9400\n",
      "Epoch 75/150\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.5150 - accuracy: 0.9400\n",
      "Epoch 76/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.5097 - accuracy: 0.9400\n",
      "Epoch 77/150\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.5042 - accuracy: 0.9400\n",
      "Epoch 78/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.4991 - accuracy: 0.9400\n",
      "Epoch 79/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.4938 - accuracy: 0.9400\n",
      "Epoch 80/150\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.4884 - accuracy: 0.9400\n",
      "Epoch 81/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.4836 - accuracy: 0.9400\n",
      "Epoch 82/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.4785 - accuracy: 0.9300\n",
      "Epoch 83/150\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.4736 - accuracy: 0.9300\n",
      "Epoch 84/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.4688 - accuracy: 0.9300\n",
      "Epoch 85/150\n",
      "100/100 [==============================] - 0s 75us/step - loss: 0.4636 - accuracy: 0.9400\n",
      "Epoch 86/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.4596 - accuracy: 0.9500\n",
      "Epoch 87/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.4553 - accuracy: 0.9500\n",
      "Epoch 88/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.4508 - accuracy: 0.9500\n",
      "Epoch 89/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.4467 - accuracy: 0.9500\n",
      "Epoch 90/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.4423 - accuracy: 0.9500\n",
      "Epoch 91/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.4376 - accuracy: 0.9500\n",
      "Epoch 92/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.4330 - accuracy: 0.9500\n",
      "Epoch 93/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.4287 - accuracy: 0.9500\n",
      "Epoch 94/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.4243 - accuracy: 0.9500\n",
      "Epoch 95/150\n",
      "100/100 [==============================] - 0s 65us/step - loss: 0.4206 - accuracy: 0.9500\n",
      "Epoch 96/150\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.4169 - accuracy: 0.9500\n",
      "Epoch 97/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.4129 - accuracy: 0.9500\n",
      "Epoch 98/150\n",
      "100/100 [==============================] - 0s 170us/step - loss: 0.4088 - accuracy: 0.9500\n",
      "Epoch 99/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.4049 - accuracy: 0.9500\n",
      "Epoch 100/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.4004 - accuracy: 0.9500\n",
      "Epoch 101/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.3978 - accuracy: 0.9500\n",
      "Epoch 102/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.3941 - accuracy: 0.9500\n",
      "Epoch 103/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.3904 - accuracy: 0.9500\n",
      "Epoch 104/150\n",
      "100/100 [==============================] - 0s 65us/step - loss: 0.3868 - accuracy: 0.9500\n",
      "Epoch 105/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.3832 - accuracy: 0.9500\n",
      "Epoch 106/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.3790 - accuracy: 0.9500\n",
      "Epoch 107/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.3761 - accuracy: 0.9500\n",
      "Epoch 108/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.3722 - accuracy: 0.9600\n",
      "Epoch 109/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.3709 - accuracy: 0.9600\n",
      "Epoch 110/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.3669 - accuracy: 0.9600\n",
      "Epoch 111/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.3628 - accuracy: 0.9600\n",
      "Epoch 112/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.3587 - accuracy: 0.9500\n",
      "Epoch 113/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.3552 - accuracy: 0.9500\n",
      "Epoch 114/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.3520 - accuracy: 0.9500\n",
      "Epoch 115/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.3491 - accuracy: 0.9500\n",
      "Epoch 116/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.3466 - accuracy: 0.9500\n",
      "Epoch 117/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.3434 - accuracy: 0.9500\n",
      "Epoch 118/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.3400 - accuracy: 0.9500\n",
      "Epoch 119/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.3361 - accuracy: 0.9500\n",
      "Epoch 120/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.3333 - accuracy: 0.9600\n",
      "Epoch 121/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.3304 - accuracy: 0.9600\n",
      "Epoch 122/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.3270 - accuracy: 0.9600\n",
      "Epoch 123/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.3239 - accuracy: 0.9600\n",
      "Epoch 124/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.3215 - accuracy: 0.9600\n",
      "Epoch 125/150\n",
      "100/100 [==============================] - 0s 65us/step - loss: 0.3182 - accuracy: 0.9600\n",
      "Epoch 126/150\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.3154 - accuracy: 0.9600\n",
      "Epoch 127/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.3125 - accuracy: 0.9600\n",
      "Epoch 128/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.3100 - accuracy: 0.9600\n",
      "Epoch 129/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.3073 - accuracy: 0.9600\n",
      "Epoch 130/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.3047 - accuracy: 0.9600\n",
      "Epoch 131/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.3022 - accuracy: 0.9600\n",
      "Epoch 132/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.2993 - accuracy: 0.9600\n",
      "Epoch 133/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.2960 - accuracy: 0.9600\n",
      "Epoch 134/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.2943 - accuracy: 0.9500\n",
      "Epoch 135/150\n",
      "100/100 [==============================] - 0s 65us/step - loss: 0.2926 - accuracy: 0.9600\n",
      "Epoch 136/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.2886 - accuracy: 0.9600\n",
      "Epoch 137/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.2867 - accuracy: 0.9600\n",
      "Epoch 138/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.2831 - accuracy: 0.9600\n",
      "Epoch 139/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.2805 - accuracy: 0.9600\n",
      "Epoch 140/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.2777 - accuracy: 0.9600\n",
      "Epoch 141/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.2762 - accuracy: 0.9700\n",
      "Epoch 142/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.2742 - accuracy: 0.9600\n",
      "Epoch 143/150\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.2715 - accuracy: 0.9600\n",
      "Epoch 144/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.2684 - accuracy: 0.9700\n",
      "Epoch 145/150\n",
      "100/100 [==============================] - 0s 65us/step - loss: 0.2654 - accuracy: 0.9600\n",
      "Epoch 146/150\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.2646 - accuracy: 0.9700\n",
      "Epoch 147/150\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.2633 - accuracy: 0.9600\n",
      "Epoch 148/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.2612 - accuracy: 0.9600\n",
      "Epoch 149/150\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.2581 - accuracy: 0.9600\n",
      "Epoch 150/150\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.2548 - accuracy: 0.9600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2a2529365c8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_s, y_train, epochs=150, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff62ab15",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1264f6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "229e04ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3fc4351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19,  0,  0],\n",
       "       [ 0, 14,  1],\n",
       "       [ 0,  0, 16]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12a45eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      0.93      0.97        15\n",
      "           2       0.94      1.00      0.97        16\n",
      "\n",
      "   micro avg       0.98      0.98      0.98        50\n",
      "   macro avg       0.98      0.98      0.98        50\n",
      "weighted avg       0.98      0.98      0.98        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0124ada3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75fe9f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('LM_model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "186e6bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec285fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = load_model('LM_model1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6355be28",
   "metadata": {},
   "source": [
    " ## Text Gen with LSTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06a66c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filepath):\n",
    "    with open(filepath) as f:\n",
    "        str_text = f.read()\n",
    "        \n",
    "    return str_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "159f08b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09b34614",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=['parser', 'tagger', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2f05e9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.max_length = 1198623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cd7d91ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_punc(doc_text):\n",
    "    return [token.text.lower() for token in nlp(doc_text) if token.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9577c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = read_file('moby_dick_four_chapters.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f431eb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = separate_punc(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5db4e1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass in 25 words, and predict 26th word\n",
    "train_len = 25 + 1\n",
    "text_sequences =[]\n",
    "\n",
    "for i in range(train_len, len(tokens)):\n",
    "    seq = tokens[i-train_len:i]\n",
    "    text_sequences.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e9a19ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['call',\n",
       " 'me',\n",
       " 'ishmael',\n",
       " 'some',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'never',\n",
       " 'mind',\n",
       " 'how',\n",
       " 'long',\n",
       " 'precisely',\n",
       " 'having',\n",
       " 'little',\n",
       " 'or',\n",
       " 'no',\n",
       " 'money',\n",
       " 'in',\n",
       " 'my',\n",
       " 'purse',\n",
       " 'and',\n",
       " 'nothing',\n",
       " 'particular',\n",
       " 'to',\n",
       " 'interest',\n",
       " 'me',\n",
       " 'on']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3bb67157",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e7f0732",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ae838ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "78be071a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[964,\n",
       " 14,\n",
       " 265,\n",
       " 51,\n",
       " 263,\n",
       " 416,\n",
       " 87,\n",
       " 222,\n",
       " 129,\n",
       " 111,\n",
       " 962,\n",
       " 262,\n",
       " 50,\n",
       " 43,\n",
       " 37,\n",
       " 321,\n",
       " 7,\n",
       " 23,\n",
       " 555,\n",
       " 3,\n",
       " 150,\n",
       " 261,\n",
       " 6,\n",
       " 2704,\n",
       " 14,\n",
       " 24]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0] # replaced each sequence with IDs for words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8f5310eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'call'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.index_word[964]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c51d1ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('call', 27),\n",
       "             ('me', 2471),\n",
       "             ('ishmael', 133),\n",
       "             ('some', 758),\n",
       "             ('years', 135),\n",
       "             ('ago', 84),\n",
       "             ('never', 449),\n",
       "             ('mind', 164),\n",
       "             ('how', 321),\n",
       "             ('long', 374),\n",
       "             ('precisely', 37),\n",
       "             ('having', 142),\n",
       "             ('little', 767),\n",
       "             ('or', 950),\n",
       "             ('no', 1029),\n",
       "             ('money', 120),\n",
       "             ('in', 5647),\n",
       "             ('my', 1812),\n",
       "             ('purse', 71),\n",
       "             ('and', 9646),\n",
       "             ('nothing', 281),\n",
       "             ('particular', 152),\n",
       "             ('to', 6497),\n",
       "             ('interest', 24),\n",
       "             ('on', 1716),\n",
       "             ('shore', 26),\n",
       "             ('i', 7176),\n",
       "             ('thought', 676),\n",
       "             ('would', 702),\n",
       "             ('sail', 104),\n",
       "             ('about', 1014),\n",
       "             ('a', 10377),\n",
       "             ('see', 442),\n",
       "             ('the', 15566),\n",
       "             ('watery', 26),\n",
       "             ('part', 234),\n",
       "             ('of', 8287),\n",
       "             ('world', 234),\n",
       "             ('it', 4394),\n",
       "             ('is', 1950),\n",
       "             ('way', 390),\n",
       "             ('have', 806),\n",
       "             ('driving', 26),\n",
       "             ('off', 416),\n",
       "             ('spleen', 26),\n",
       "             ('regulating', 26),\n",
       "             ('circulation', 26),\n",
       "             ('whenever', 130),\n",
       "             ('find', 78),\n",
       "             ('myself', 416),\n",
       "             ('growing', 26),\n",
       "             ('grim', 26),\n",
       "             ('mouth', 130),\n",
       "             ('damp', 78),\n",
       "             ('drizzly', 26),\n",
       "             ('november', 26),\n",
       "             ('soul', 78),\n",
       "             ('involuntarily', 52),\n",
       "             ('pausing', 52),\n",
       "             ('before', 364),\n",
       "             ('coffin', 130),\n",
       "             ('warehouses', 52),\n",
       "             ('bringing', 26),\n",
       "             ('up', 1237),\n",
       "             ('rear', 26),\n",
       "             ('every', 182),\n",
       "             ('funeral', 26),\n",
       "             ('meet', 26),\n",
       "             ('especially', 104),\n",
       "             ('hypos', 26),\n",
       "             ('get', 364),\n",
       "             ('such', 572),\n",
       "             ('an', 806),\n",
       "             ('upper', 26),\n",
       "             ('hand', 312),\n",
       "             ('that', 3770),\n",
       "             ('requires', 52),\n",
       "             ('strong', 78),\n",
       "             ('moral', 26),\n",
       "             ('principle', 26),\n",
       "             ('prevent', 26),\n",
       "             ('from', 1508),\n",
       "             ('deliberately', 26),\n",
       "             ('stepping', 26),\n",
       "             ('into', 988),\n",
       "             ('street', 104),\n",
       "             ('methodically', 26),\n",
       "             ('knocking', 26),\n",
       "             ('people', 52),\n",
       "             (\"'s\", 1691),\n",
       "             ('hats', 26),\n",
       "             ('then', 832),\n",
       "             ('account', 78),\n",
       "             ('high', 130),\n",
       "             ('time', 520),\n",
       "             ('sea', 546),\n",
       "             ('as', 2366),\n",
       "             ('soon', 234),\n",
       "             ('can', 338),\n",
       "             ('this', 2184),\n",
       "             ('substitute', 26),\n",
       "             ('for', 1820),\n",
       "             ('pistol', 26),\n",
       "             ('ball', 26),\n",
       "             ('with', 2392),\n",
       "             ('philosophical', 26),\n",
       "             ('flourish', 26),\n",
       "             ('cato', 26),\n",
       "             ('throws', 26),\n",
       "             ('himself', 338),\n",
       "             ('upon', 780),\n",
       "             ('his', 3139),\n",
       "             ('sword', 78),\n",
       "             ('quietly', 78),\n",
       "             ('take', 260),\n",
       "             ('ship', 182),\n",
       "             ('there', 1456),\n",
       "             ('surprising', 26),\n",
       "             ('if', 728),\n",
       "             ('they', 728),\n",
       "             ('but', 2704),\n",
       "             ('knew', 130),\n",
       "             ('almost', 286),\n",
       "             ('all', 1872),\n",
       "             ('men', 130),\n",
       "             ('their', 390),\n",
       "             ('degree', 78),\n",
       "             ('other', 494),\n",
       "             ('cherish', 26),\n",
       "             ('very', 494),\n",
       "             ('nearly', 52),\n",
       "             ('same', 312),\n",
       "             ('feelings', 26),\n",
       "             ('towards', 260),\n",
       "             ('ocean', 52),\n",
       "             ('now', 1040),\n",
       "             ('your', 442),\n",
       "             ('insular', 26),\n",
       "             ('city', 104),\n",
       "             ('manhattoes', 26),\n",
       "             ('belted', 26),\n",
       "             ('round', 364),\n",
       "             ('by', 962),\n",
       "             ('wharves', 26),\n",
       "             ('indian', 52),\n",
       "             ('isles', 26),\n",
       "             ('coral', 26),\n",
       "             ('reefs', 26),\n",
       "             ('commerce', 26),\n",
       "             ('surrounds', 26),\n",
       "             ('her', 156),\n",
       "             ('surf', 26),\n",
       "             ('right', 156),\n",
       "             ('left', 78),\n",
       "             ('streets', 208),\n",
       "             ('you', 2210),\n",
       "             ('waterward', 52),\n",
       "             ('its', 156),\n",
       "             ('extreme', 26),\n",
       "             ('downtown', 26),\n",
       "             ('battery', 52),\n",
       "             ('where', 364),\n",
       "             ('noble', 52),\n",
       "             ('mole', 26),\n",
       "             ('washed', 52),\n",
       "             ('waves', 26),\n",
       "             ('cooled', 26),\n",
       "             ('breezes', 26),\n",
       "             ('which', 572),\n",
       "             ('few', 104),\n",
       "             ('hours', 130),\n",
       "             ('previous', 104),\n",
       "             ('were', 962),\n",
       "             ('out', 956),\n",
       "             ('sight', 104),\n",
       "             ('land', 208),\n",
       "             ('look', 156),\n",
       "             ('at', 2184),\n",
       "             ('crowds', 52),\n",
       "             ('water', 260),\n",
       "             ('gazers', 26),\n",
       "             ('circumambulate', 26),\n",
       "             ('dreamy', 26),\n",
       "             ('sabbath', 52),\n",
       "             ('afternoon', 52),\n",
       "             ('go', 494),\n",
       "             ('corlears', 26),\n",
       "             ('hook', 26),\n",
       "             ('coenties', 26),\n",
       "             ('slip', 26),\n",
       "             ('thence', 52),\n",
       "             ('whitehall', 26),\n",
       "             ('northward', 26),\n",
       "             ('what', 1170),\n",
       "             ('do', 702),\n",
       "             ('?--', 182),\n",
       "             ('posted', 26),\n",
       "             ('like', 732),\n",
       "             ('silent', 52),\n",
       "             ('sentinels', 26),\n",
       "             ('around', 78),\n",
       "             ('town', 182),\n",
       "             ('stand', 182),\n",
       "             ('thousands', 52),\n",
       "             ('mortal', 26),\n",
       "             ('fixed', 78),\n",
       "             ('reveries', 52),\n",
       "             ('leaning', 52),\n",
       "             ('against', 234),\n",
       "             ('spiles', 26),\n",
       "             ('seated', 52),\n",
       "             ('pier', 26),\n",
       "             ('heads', 338),\n",
       "             ('looking', 312),\n",
       "             ('over', 702),\n",
       "             ('bulwarks', 52),\n",
       "             ('ships', 78),\n",
       "             ('china', 26),\n",
       "             ('aloft', 52),\n",
       "             ('rigging', 26),\n",
       "             ('striving', 26),\n",
       "             ('still', 364),\n",
       "             ('better', 208),\n",
       "             ('seaward', 26),\n",
       "             ('peep', 26),\n",
       "             ('these', 494),\n",
       "             ('are', 416),\n",
       "             ('landsmen', 26),\n",
       "             ('week', 52),\n",
       "             ('days', 104),\n",
       "             ('pent', 26),\n",
       "             ('lath', 26),\n",
       "             ('plaster', 52),\n",
       "             ('tied', 26),\n",
       "             ('counters', 26),\n",
       "             ('nailed', 26),\n",
       "             ('benches', 26),\n",
       "             ('clinched', 26),\n",
       "             ('desks', 26),\n",
       "             ('green', 130),\n",
       "             ('fields', 26),\n",
       "             ('gone', 52),\n",
       "             ('here', 624),\n",
       "             ('come', 338),\n",
       "             ('more', 494),\n",
       "             ('pacing', 26),\n",
       "             ('straight', 104),\n",
       "             ('seemingly', 26),\n",
       "             ('bound', 52),\n",
       "             ('dive', 26),\n",
       "             ('strange', 182),\n",
       "             ('will', 260),\n",
       "             ('content', 52),\n",
       "             ('them', 442),\n",
       "             ('extremest', 26),\n",
       "             ('limit', 26),\n",
       "             ('loitering', 26),\n",
       "             ('under', 260),\n",
       "             ('shady', 26),\n",
       "             ('lee', 26),\n",
       "             ('yonder', 52),\n",
       "             ('not', 1534),\n",
       "             ('suffice', 26),\n",
       "             ('must', 442),\n",
       "             ('just', 390),\n",
       "             ('nigh', 104),\n",
       "             ('possibly', 26),\n",
       "             ('without', 182),\n",
       "             ('falling', 52),\n",
       "             ('miles', 78),\n",
       "             ('leagues', 26),\n",
       "             ('inlanders', 26),\n",
       "             ('lanes', 26),\n",
       "             ('alleys', 26),\n",
       "             ('avenues', 26),\n",
       "             ('north', 52),\n",
       "             ('east', 26),\n",
       "             ('south', 156),\n",
       "             ('west', 26),\n",
       "             ('yet', 416),\n",
       "             ('unite', 26),\n",
       "             ('tell', 442),\n",
       "             ('does', 156),\n",
       "             ('magnetic', 26),\n",
       "             ('virtue', 26),\n",
       "             ('needles', 26),\n",
       "             ('compasses', 26),\n",
       "             ('those', 234),\n",
       "             ('attract', 26),\n",
       "             ('thither', 26),\n",
       "             ('once', 208),\n",
       "             ('say', 286),\n",
       "             ('country', 78),\n",
       "             ('lakes', 26),\n",
       "             ('any', 364),\n",
       "             ('path', 26),\n",
       "             ('please', 52),\n",
       "             ('ten', 52),\n",
       "             ('one', 1300),\n",
       "             ('carries', 26),\n",
       "             ('down', 468),\n",
       "             ('dale', 26),\n",
       "             ('leaves', 52),\n",
       "             ('pool', 26),\n",
       "             ('stream', 78),\n",
       "             ('magic', 52),\n",
       "             ('let', 156),\n",
       "             ('most', 468),\n",
       "             ('absent', 26),\n",
       "             ('minded', 26),\n",
       "             ('be', 1716),\n",
       "             ('plunged', 52),\n",
       "             ('deepest', 26),\n",
       "             ('man', 572),\n",
       "             ('legs', 104),\n",
       "             ('set', 156),\n",
       "             ('feet', 182),\n",
       "             ('going', 260),\n",
       "             ('he', 3273),\n",
       "             ('infallibly', 26),\n",
       "             ('lead', 78),\n",
       "             ('region', 26),\n",
       "             ('should', 286),\n",
       "             ('ever', 338),\n",
       "             ('athirst', 26),\n",
       "             ('great', 376),\n",
       "             ('american', 78),\n",
       "             ('desert', 26),\n",
       "             ('try', 104),\n",
       "             ('experiment', 26),\n",
       "             ('caravan', 26),\n",
       "             ('happen', 26),\n",
       "             ('supplied', 26),\n",
       "             ('metaphysical', 52),\n",
       "             ('professor', 26),\n",
       "             ('yes', 104),\n",
       "             ('knows', 26),\n",
       "             ('meditation', 26),\n",
       "             ('wedded', 26),\n",
       "             ('artist', 78),\n",
       "             ('desires', 26),\n",
       "             ('paint', 26),\n",
       "             ('dreamiest', 26),\n",
       "             ('shadiest', 26),\n",
       "             ('quietest', 26),\n",
       "             ('enchanting', 26),\n",
       "             ('bit', 130),\n",
       "             ('romantic', 26),\n",
       "             ('landscape', 26),\n",
       "             ('valley', 26),\n",
       "             ('saco', 26),\n",
       "             ('chief', 52),\n",
       "             ('element', 26),\n",
       "             ('employs', 26),\n",
       "             ('trees', 26),\n",
       "             ('each', 78),\n",
       "             ('hollow', 26),\n",
       "             ('trunk', 52),\n",
       "             ('hermit', 26),\n",
       "             ('crucifix', 26),\n",
       "             ('within', 130),\n",
       "             ('sleeps', 26),\n",
       "             ('meadow', 52),\n",
       "             ('sleep', 416),\n",
       "             ('cattle', 26),\n",
       "             ('cottage', 26),\n",
       "             ('goes', 78),\n",
       "             ('sleepy', 26),\n",
       "             ('smoke', 52),\n",
       "             ('deep', 78),\n",
       "             ('distant', 78),\n",
       "             ('woodlands', 26),\n",
       "             ('winds', 78),\n",
       "             ('mazy', 26),\n",
       "             ('reaching', 52),\n",
       "             ('overlapping', 26),\n",
       "             ('spurs', 26),\n",
       "             ('mountains', 26),\n",
       "             ('bathed', 26),\n",
       "             ('hill', 52),\n",
       "             ('side', 286),\n",
       "             ('blue', 78),\n",
       "             ('though', 546),\n",
       "             ('picture', 130),\n",
       "             ('lies', 26),\n",
       "             ('thus', 52),\n",
       "             ('tranced', 26),\n",
       "             ('pine', 52),\n",
       "             ('tree', 26),\n",
       "             ('shakes', 26),\n",
       "             ('sighs', 52),\n",
       "             ('shepherd', 52),\n",
       "             ('head', 624),\n",
       "             ('vain', 26),\n",
       "             ('unless', 104),\n",
       "             ('eye', 26),\n",
       "             ('him', 1092),\n",
       "             ('visit', 26),\n",
       "             ('prairies', 26),\n",
       "             ('june', 52),\n",
       "             ('when', 650),\n",
       "             ('scores', 52),\n",
       "             ('wade', 26),\n",
       "             ('knee', 26),\n",
       "             ('among', 78),\n",
       "             ('tiger', 26),\n",
       "             ('lilies', 26),\n",
       "             ('charm', 26),\n",
       "             ('wanting', 26),\n",
       "             ('drop', 26),\n",
       "             ('niagara', 26),\n",
       "             ('cataract', 26),\n",
       "             ('sand', 26),\n",
       "             ('travel', 26),\n",
       "             ('thousand', 52),\n",
       "             ('why', 286),\n",
       "             ('did', 572),\n",
       "             ('poor', 104),\n",
       "             ('poet', 26),\n",
       "             ('tennessee', 26),\n",
       "             ('suddenly', 78),\n",
       "             ('receiving', 26),\n",
       "             ('two', 338),\n",
       "             ('handfuls', 26),\n",
       "             ('silver', 52),\n",
       "             ('deliberate', 26),\n",
       "             ('whether', 182),\n",
       "             ('buy', 26),\n",
       "             ('coat', 104),\n",
       "             ('sadly', 52),\n",
       "             ('needed', 26),\n",
       "             ('invest', 26),\n",
       "             ('pedestrian', 26),\n",
       "             ('trip', 26),\n",
       "             ('rockaway', 26),\n",
       "             ('beach', 26),\n",
       "             ('robust', 52),\n",
       "             ('healthy', 52),\n",
       "             ('boy', 52),\n",
       "             ('crazy', 52),\n",
       "             ('first', 494),\n",
       "             ('voyage', 208),\n",
       "             ('passenger', 104),\n",
       "             ('yourself', 156),\n",
       "             ('feel', 78),\n",
       "             ('mystical', 26),\n",
       "             ('vibration', 26),\n",
       "             ('told', 130),\n",
       "             ('old', 754),\n",
       "             ('persians', 26),\n",
       "             ('hold', 52),\n",
       "             ('holy', 52),\n",
       "             ('greeks', 26),\n",
       "             ('give', 208),\n",
       "             ('separate', 26),\n",
       "             ('deity', 26),\n",
       "             ('own', 286),\n",
       "             ('brother', 52),\n",
       "             ('jove', 26),\n",
       "             ('surely', 26),\n",
       "             ('meaning', 78),\n",
       "             ('deeper', 26),\n",
       "             ('story', 130),\n",
       "             ('narcissus', 26),\n",
       "             ('who', 416),\n",
       "             ('because', 182),\n",
       "             ('could', 650),\n",
       "             ('grasp', 26),\n",
       "             ('tormenting', 26),\n",
       "             ('mild', 26),\n",
       "             ('image', 156),\n",
       "             ('saw', 156),\n",
       "             ('fountain', 26),\n",
       "             ('was', 2886),\n",
       "             ('drowned', 26),\n",
       "             ('we', 286),\n",
       "             ('ourselves', 52),\n",
       "             ('rivers', 26),\n",
       "             ('oceans', 26),\n",
       "             ('ungraspable', 26),\n",
       "             ('phantom', 78),\n",
       "             ('life', 78),\n",
       "             ('key', 26),\n",
       "             ('am', 156),\n",
       "             ('habit', 26),\n",
       "             ('begin', 52),\n",
       "             ('grow', 52),\n",
       "             ('hazy', 26),\n",
       "             ('eyes', 182),\n",
       "             ('conscious', 26),\n",
       "             ('lungs', 26),\n",
       "             ('mean', 130),\n",
       "             ('inferred', 52),\n",
       "             ('needs', 52),\n",
       "             ('rag', 26),\n",
       "             ('something', 312),\n",
       "             ('besides', 156),\n",
       "             ('passengers', 78),\n",
       "             ('sick', 26),\n",
       "             ('quarrelsome', 26),\n",
       "             (\"don't\", 52),\n",
       "             ('nights', 26),\n",
       "             ('enjoy', 26),\n",
       "             ('themselves', 52),\n",
       "             ('much', 442),\n",
       "             ('general', 26),\n",
       "             ('thing', 130),\n",
       "             (';--', 104),\n",
       "             ('nor', 78),\n",
       "             ('salt', 26),\n",
       "             ('commodore', 52),\n",
       "             ('captain', 52),\n",
       "             ('cook', 78),\n",
       "             ('abandon', 26),\n",
       "             ('glory', 52),\n",
       "             ('distinction', 26),\n",
       "             ('offices', 26),\n",
       "             ('abominate', 26),\n",
       "             ('honourable', 26),\n",
       "             ('respectable', 26),\n",
       "             ('toils', 26),\n",
       "             ('trials', 26),\n",
       "             ('tribulations', 26),\n",
       "             ('kind', 78),\n",
       "             ('whatsoever', 52),\n",
       "             ('quite', 78),\n",
       "             ('care', 78),\n",
       "             ('taking', 104),\n",
       "             ('barques', 26),\n",
       "             ('brigs', 26),\n",
       "             ('schooners', 26),\n",
       "             (',--', 130),\n",
       "             ('confess', 52),\n",
       "             ('considerable', 26),\n",
       "             ('being', 390),\n",
       "             ('sort', 494),\n",
       "             ('officer', 52),\n",
       "             ('board', 78),\n",
       "             ('somehow', 78),\n",
       "             ('fancied', 26),\n",
       "             ('broiling', 26),\n",
       "             ('fowls', 26),\n",
       "             ('broiled', 78),\n",
       "             ('judiciously', 26),\n",
       "             ('buttered', 26),\n",
       "             ('judgmatically', 26),\n",
       "             ('salted', 26),\n",
       "             ('peppered', 26),\n",
       "             ('speak', 130),\n",
       "             ('respectfully', 52),\n",
       "             ('reverentially', 26),\n",
       "             ('fowl', 26),\n",
       "             ('than', 390),\n",
       "             ('idolatrous', 26),\n",
       "             ('dotings', 26),\n",
       "             ('egyptians', 26),\n",
       "             ('ibis', 26),\n",
       "             ('roasted', 26),\n",
       "             ('river', 26),\n",
       "             ('horse', 52),\n",
       "             ('mummies', 26),\n",
       "             ('creatures', 26),\n",
       "             ('huge', 52),\n",
       "             ('bake', 26),\n",
       "             ('houses', 52),\n",
       "             ('pyramids', 26),\n",
       "             ('simple', 26),\n",
       "             ('sailor', 156),\n",
       "             ('mast', 78),\n",
       "             ('plumb', 26),\n",
       "             ('forecastle', 52),\n",
       "             ('royal', 26),\n",
       "             ('true', 104),\n",
       "             ('rather', 260),\n",
       "             ('order', 130),\n",
       "             ('make', 260),\n",
       "             ('jump', 52),\n",
       "             ('spar', 52),\n",
       "             ('grasshopper', 26),\n",
       "             ('may', 312),\n",
       "             ('unpleasant', 26),\n",
       "             ('enough', 338),\n",
       "             ('touches', 26),\n",
       "             ('sense', 78),\n",
       "             ('honour', 26),\n",
       "             ('particularly', 52),\n",
       "             ('established', 26),\n",
       "             ('family', 26),\n",
       "             ('van', 26),\n",
       "             ('rensselaers', 26),\n",
       "             ('randolphs', 26),\n",
       "             ('hardicanutes', 26),\n",
       "             ('putting', 52),\n",
       "             ('tar', 52),\n",
       "             ('pot', 26),\n",
       "             ('been', 468),\n",
       "             ('lording', 26),\n",
       "             ('schoolmaster', 52),\n",
       "             ('making', 130),\n",
       "             ('tallest', 26),\n",
       "             ('boys', 52),\n",
       "             ('awe', 26),\n",
       "             ('transition', 52),\n",
       "             ('keen', 26),\n",
       "             ('assure', 26),\n",
       "             ('decoction', 26),\n",
       "             ('seneca', 26),\n",
       "             ('stoics', 26),\n",
       "             ('enable', 26),\n",
       "             ('grin', 52),\n",
       "             ('bear', 52),\n",
       "             ('even', 130),\n",
       "             ('wears', 26),\n",
       "             ('hunks', 52),\n",
       "             ('orders', 26),\n",
       "             ('broom', 26),\n",
       "             ('sweep', 52),\n",
       "             ('decks', 26),\n",
       "             ('indignity', 26),\n",
       "             ('amount', 26),\n",
       "             ('weighed', 52),\n",
       "             ('scales', 26),\n",
       "             ('new', 286),\n",
       "             ('testament', 26),\n",
       "             ('think', 182),\n",
       "             ('archangel', 26),\n",
       "             ('gabriel', 26),\n",
       "             ('thinks', 182),\n",
       "             ('anything', 52),\n",
       "             ('less', 52),\n",
       "             ('promptly', 26),\n",
       "             ('obey', 26),\n",
       "             ('instance', 26),\n",
       "             ('ai', 104),\n",
       "             (\"n't\", 624),\n",
       "             ('slave', 26),\n",
       "             ('well', 208),\n",
       "             ('however', 208),\n",
       "             ('captains', 26),\n",
       "             ('thump', 52),\n",
       "             ('punch', 26),\n",
       "             ('satisfaction', 26),\n",
       "             ('knowing', 78),\n",
       "             ('everybody', 26),\n",
       "             ('else', 208),\n",
       "             ('served', 26),\n",
       "             ('either', 78),\n",
       "             ('physical', 26),\n",
       "             ('point', 52),\n",
       "             ('view', 52),\n",
       "             ('so', 1092),\n",
       "             ('universal', 26),\n",
       "             ('passed', 78),\n",
       "             ('hands', 78),\n",
       "             ('rub', 26),\n",
       "             ('shoulder', 26),\n",
       "             ('blades', 26),\n",
       "             ('again', 286),\n",
       "             ('always', 104),\n",
       "             ('paying', 78),\n",
       "             ('trouble', 26),\n",
       "             ('whereas', 26),\n",
       "             ('pay', 78),\n",
       "             ('single', 52),\n",
       "             ('penny', 78),\n",
       "             ('heard', 208),\n",
       "             ('contrary', 26),\n",
       "             ('difference', 52),\n",
       "             ('between', 234),\n",
       "             ('paid', 52),\n",
       "             ('act', 52),\n",
       "             ('perhaps', 130),\n",
       "             ('uncomfortable', 52),\n",
       "             ('infliction', 26),\n",
       "             ('orchard', 26),\n",
       "             ('thieves', 26),\n",
       "             ('entailed', 26),\n",
       "             ('us', 104),\n",
       "             ('compare', 52),\n",
       "             ('urbane', 26),\n",
       "             ('activity', 26),\n",
       "             ('receives', 26),\n",
       "             ('really', 104),\n",
       "             ('marvellous', 104),\n",
       "             ('considering', 26),\n",
       "             ('earnestly', 26),\n",
       "             ('believe', 26),\n",
       "             ('root', 26),\n",
       "             ('earthly', 52),\n",
       "             ('ills', 26),\n",
       "             ('monied', 26),\n",
       "             ('enter', 52),\n",
       "             ('heaven', 104),\n",
       "             ('ah', 26),\n",
       "             ('cheerfully', 26),\n",
       "             ('consign', 26),\n",
       "             ('perdition', 26),\n",
       "             ('finally', 26),\n",
       "             ('wholesome', 26),\n",
       "             ('exercise', 26),\n",
       "             ('pure', 26),\n",
       "             ('air', 104),\n",
       "             ('fore', 26),\n",
       "             ('castle', 26),\n",
       "             ('deck', 52),\n",
       "             ('far', 104),\n",
       "             ('prevalent', 26),\n",
       "             ('astern', 26),\n",
       "             ('violate', 26),\n",
       "             ('pythagorean', 26),\n",
       "             ('maxim', 26),\n",
       "             ('quarter', 52),\n",
       "             ('gets', 26),\n",
       "             ('atmosphere', 26),\n",
       "             ('second', 104),\n",
       "             ('sailors', 78),\n",
       "             ('breathes', 26),\n",
       "             ('commonalty', 26),\n",
       "             ('leaders', 52),\n",
       "             ('many', 104),\n",
       "             ('things', 130),\n",
       "             ('suspect', 26),\n",
       "             ('wherefore', 26),\n",
       "             ('after', 234),\n",
       "             ('repeatedly', 26),\n",
       "             ('smelt', 52),\n",
       "             ('merchant', 26),\n",
       "             ('whaling', 234),\n",
       "             ('invisible', 26),\n",
       "             ('police', 26),\n",
       "             ('fates', 52),\n",
       "             ('has', 104),\n",
       "             ('constant', 26),\n",
       "             ('surveillance', 26),\n",
       "             ('secretly', 26),\n",
       "             ('dogs', 26),\n",
       "             ('influences', 26),\n",
       "             ('unaccountable', 104),\n",
       "             ('answer', 130),\n",
       "             ('doubtless', 52),\n",
       "             ('formed', 52),\n",
       "             ('grand', 104),\n",
       "             ('programme', 26),\n",
       "             ('providence', 26),\n",
       "             ('drawn', 26),\n",
       "             ('came', 286),\n",
       "             ('brief', 26),\n",
       "             ('interlude', 26),\n",
       "             ('solo', 26),\n",
       "             ('extensive', 26),\n",
       "             ('performances', 26),\n",
       "             ('bill', 26),\n",
       "             ('run', 52),\n",
       "             ('contested', 26),\n",
       "             ('election', 26),\n",
       "             ('presidency', 26),\n",
       "             ('united', 26),\n",
       "             ('states', 26),\n",
       "             ('bloody', 26),\n",
       "             ('battle', 26),\n",
       "             ('affghanistan', 26),\n",
       "             ('exactly', 78),\n",
       "             ('stage', 52),\n",
       "             ('managers', 26),\n",
       "             ('put', 208),\n",
       "             ('shabby', 52),\n",
       "             ('others', 52),\n",
       "             ('magnificent', 26),\n",
       "             ('parts', 130),\n",
       "             ('tragedies', 26),\n",
       "             ('short', 78),\n",
       "             ('easy', 78),\n",
       "             ('genteel', 26),\n",
       "             ('comedies', 26),\n",
       "             ('jolly', 104),\n",
       "             ('farces', 26),\n",
       "             ('recall', 26),\n",
       "             ('circumstances', 52),\n",
       "             ('springs', 26),\n",
       "             ('motives', 52),\n",
       "             ('cunningly', 26),\n",
       "             ('presented', 26),\n",
       "             ('various', 52),\n",
       "             ('disguises', 26),\n",
       "             ('induced', 26),\n",
       "             ('performing', 26),\n",
       "             ('cajoling', 26),\n",
       "             ('delusion', 26),\n",
       "             ('choice', 26),\n",
       "             ('resulting', 26),\n",
       "             ('unbiased', 26),\n",
       "             ('freewill', 26),\n",
       "             ('discriminating', 26),\n",
       "             ('judgment', 26),\n",
       "             ('overwhelming', 26),\n",
       "             ('idea', 182),\n",
       "             ('whale', 260),\n",
       "             ('portentous', 78),\n",
       "             ('mysterious', 52),\n",
       "             ('monster', 26),\n",
       "             ('roused', 26),\n",
       "             ('curiosity', 52),\n",
       "             ('wild', 130),\n",
       "             ('seas', 156),\n",
       "             ('rolled', 156),\n",
       "             ('island', 78),\n",
       "             ('bulk', 26),\n",
       "             ('undeliverable', 26),\n",
       "             ('nameless', 78),\n",
       "             ('perils', 26),\n",
       "             ('attending', 26),\n",
       "             ('marvels', 26),\n",
       "             ('patagonian', 26),\n",
       "             ('sights', 26),\n",
       "             ('sounds', 78),\n",
       "             ('helped', 26),\n",
       "             ('sway', 26),\n",
       "             ('wish', 26),\n",
       "             ('inducements', 26),\n",
       "             ('tormented', 52),\n",
       "             ('everlasting', 52),\n",
       "             ('itch', 26),\n",
       "             ('remote', 26),\n",
       "             ('love', 26),\n",
       "             ('forbidden', 26),\n",
       "             ('barbarous', 26),\n",
       "             ('coasts', 26),\n",
       "             ('ignoring', 26),\n",
       "             ('good', 442),\n",
       "             ('quick', 26),\n",
       "             ('perceive', 26),\n",
       "             ('horror', 26),\n",
       "             ('social', 26),\n",
       "             ('since', 78),\n",
       "             ('friendly', 26),\n",
       "             ('terms', 26),\n",
       "             ('inmates', 26),\n",
       "             ('place', 390),\n",
       "             ('lodges', 26),\n",
       "             ('reason', 130),\n",
       "             ('welcome', 26),\n",
       "             ('flood', 26),\n",
       "             ('gates', 26),\n",
       "             ('wonder', 52),\n",
       "             ('swung', 26),\n",
       "             ('open', 104),\n",
       "             ('conceits', 26),\n",
       "             ('swayed', 26),\n",
       "             ('purpose', 52),\n",
       "             ('floated', 52),\n",
       "             ('inmost', 26),\n",
       "             ('endless', 26),\n",
       "             ('processions', 26),\n",
       "             ('mid', 26),\n",
       "             ('hooded', 26),\n",
       "             ('snow', 78),\n",
       "             ('stuffed', 52),\n",
       "             ('shirt', 104),\n",
       "             ('carpet', 26),\n",
       "             ('bag', 182),\n",
       "             ('tucked', 26),\n",
       "             ('arm', 286),\n",
       "             ('started', 26),\n",
       "             ('cape', 104),\n",
       "             ('horn', 52),\n",
       "             ('pacific', 26),\n",
       "             ('quitting', 26),\n",
       "             ('manhatto', 26),\n",
       "             ('duly', 26),\n",
       "             ('arrived', 52),\n",
       "             ('bedford', 104),\n",
       "             ('saturday', 78),\n",
       "             ('night', 624),\n",
       "             ('december', 26),\n",
       "             ('disappointed', 26),\n",
       "             ('learning', 26),\n",
       "             ('packet', 26),\n",
       "             ('nantucket', 182),\n",
       "             ('had', 858),\n",
       "             ('already', 26),\n",
       "             ('sailed', 26),\n",
       "             ('offer', 52),\n",
       "             ('till', 156),\n",
       "             ('following', 52),\n",
       "             ('monday', 26),\n",
       "             ('young', 130),\n",
       "             ('candidates', 26),\n",
       "             ('pains', 26),\n",
       "             ('penalties', 26),\n",
       "             ('stop', 208),\n",
       "             ('embark', 52),\n",
       "             ('related', 26),\n",
       "             ('doing', 26),\n",
       "             ('made', 338),\n",
       "             ('craft', 130),\n",
       "             ('fine', 104),\n",
       "             ('boisterous', 26),\n",
       "             ('everything', 26),\n",
       "             ('connected', 26),\n",
       "             ('famous', 26),\n",
       "             ('amazingly', 26),\n",
       "             ('pleased', 52),\n",
       "             ('late', 182),\n",
       "             ('gradually', 26),\n",
       "             ('monopolising', 26),\n",
       "             ('business', 130),\n",
       "             ('matter', 78),\n",
       "             ('behind', 26),\n",
       "             ('original', 52),\n",
       "             ('tyre', 26),\n",
       "             ('carthage', 26),\n",
       "             ('dead', 130),\n",
       "             ('stranded', 52),\n",
       "             ('aboriginal', 26),\n",
       "             ('whalemen', 26),\n",
       "             ('red', 78),\n",
       "             ('sally', 26),\n",
       "             ('canoes', 26),\n",
       "             ('chase', 26),\n",
       "             ('leviathan', 52),\n",
       "             ('too', 364),\n",
       "             ('adventurous', 26),\n",
       "             ('sloop', 26),\n",
       "             ('forth', 26),\n",
       "             ('partly', 78),\n",
       "             ('laden', 26),\n",
       "             ('imported', 26),\n",
       "             ('cobblestones', 26),\n",
       "             ('throw', 26),\n",
       "             ('whales', 52),\n",
       "             ('discover', 26),\n",
       "             ('risk', 26),\n",
       "             ('harpoon', 135),\n",
       "             ('bowsprit', 26),\n",
       "             ('day', 156),\n",
       "             ('another', 130),\n",
       "             ('ere', 78),\n",
       "             ('destined', 26),\n",
       "             ('port', 26),\n",
       "             ('became', 78),\n",
       "             ('concernment', 26),\n",
       "             ('eat', 26),\n",
       "             ('meanwhile', 78),\n",
       "             ('dubious', 26),\n",
       "             ('nay', 52),\n",
       "             ('dark', 208),\n",
       "             ('dismal', 52),\n",
       "             ('bitingly', 26),\n",
       "             ('cold', 182),\n",
       "             ('cheerless', 26),\n",
       "             ('anxious', 26),\n",
       "             ('grapnels', 26),\n",
       "             ('sounded', 26),\n",
       "             ('pocket', 78),\n",
       "             ('only', 364),\n",
       "             ('brought', 26),\n",
       "             ('pieces', 26),\n",
       "             ('wherever', 52),\n",
       "             ('said', 494),\n",
       "             ('stood', 260),\n",
       "             ('middle', 130),\n",
       "             ('dreary', 52),\n",
       "             ('shouldering', 26),\n",
       "             ('comparing', 26),\n",
       "             ('gloom', 26),\n",
       "             ('darkness', 78),\n",
       "             ('wisdom', 26),\n",
       "             ('conclude', 26),\n",
       "             ('lodge', 26),\n",
       "             ('dear', 26),\n",
       "             ('sure', 130),\n",
       "             ('inquire', 26),\n",
       "             ('price', 26),\n",
       "             ('halting', 26),\n",
       "             ('steps', 26),\n",
       "             ('paced', 26),\n",
       "             ('sign', 156),\n",
       "             ('crossed', 52),\n",
       "             ('harpoons', 78),\n",
       "             ('\"--', 78),\n",
       "             ('looked', 156),\n",
       "             ('expensive', 52),\n",
       "             ('further', 104),\n",
       "             ('bright', 52),\n",
       "             ('windows', 52),\n",
       "             ('fish', 104),\n",
       "             ('inn', 104),\n",
       "             ('fervent', 26),\n",
       "             ('rays', 26),\n",
       "             ('seemed', 416),\n",
       "             ('melted', 26),\n",
       "             ('packed', 52),\n",
       "             ('ice', 104),\n",
       "             ('house', 286),\n",
       "             ('everywhere', 26),\n",
       "             ('congealed', 26),\n",
       "             ('frost', 104),\n",
       "             ('lay', 234),\n",
       "             ('inches', 52),\n",
       "             ('thick', 52),\n",
       "             ...])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dd0603c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = len(tokenizer.word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "17e86d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2709"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a4a7bd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "684b0c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 964,   14,  265, ..., 2704,   14,   24],\n",
       "       [  14,  265,   51, ...,   14,   24,  965],\n",
       "       [ 265,   51,  263, ...,   24,  965,    5],\n",
       "       ...,\n",
       "       [ 960,   12,  168, ...,  264,   53,    2],\n",
       "       [  12,  168, 2703, ...,   53,    2, 2709],\n",
       "       [ 168, 2703,    3, ...,    2, 2709,   26]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fd8c33b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sequences[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d92708f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "caceb9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y, num_classes=vocabulary_size+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f4e4be79",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "48783c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "360d5ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocabulary_size, seq_len):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocabulary_size, seq_len, input_length=seq_len))\n",
    "    model.add(LSTM(seq_len*4, return_sequences=True))\n",
    "    model.add(LSTM(seq_len*4))\n",
    "    model.add(Dense(seq_len*4, activation='relu'))\n",
    "    model.add(Dense(vocabulary_size, activation='softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5209dc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 25, 25)            67750     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 25, 100)           50400     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2710)              273710    \n",
      "=================================================================\n",
      "Total params: 482,360\n",
      "Trainable params: 482,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(vocabulary_size+1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e8b24ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bd8aa227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 5.6492 - accuracy: 0.0764\n",
      "Epoch 2/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 5.5949 - accuracy: 0.0787\n",
      "Epoch 3/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 5.5488 - accuracy: 0.0796\n",
      "Epoch 4/200\n",
      "11368/11368 [==============================] - 14s 1ms/step - loss: 5.4989 - accuracy: 0.0812\n",
      "Epoch 5/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 5.4513 - accuracy: 0.0825\n",
      "Epoch 6/200\n",
      "11368/11368 [==============================] - 14s 1ms/step - loss: 5.4068 - accuracy: 0.0853\n",
      "Epoch 7/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 5.3644 - accuracy: 0.0840\n",
      "Epoch 8/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 5.3247 - accuracy: 0.0872\n",
      "Epoch 9/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 5.2897 - accuracy: 0.0863\n",
      "Epoch 10/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 5.2536 - accuracy: 0.0882\n",
      "Epoch 11/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 5.2178 - accuracy: 0.0912\n",
      "Epoch 12/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 5.1844 - accuracy: 0.0924\n",
      "Epoch 13/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 5.1491 - accuracy: 0.0925\n",
      "Epoch 14/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 5.1141 - accuracy: 0.0941\n",
      "Epoch 15/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 5.0852 - accuracy: 0.0926\n",
      "Epoch 16/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 5.0503 - accuracy: 0.0936\n",
      "Epoch 17/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 5.0138 - accuracy: 0.0968\n",
      "Epoch 18/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 4.9811 - accuracy: 0.0958\n",
      "Epoch 19/200\n",
      "11368/11368 [==============================] - 14s 1ms/step - loss: 4.9463 - accuracy: 0.0955\n",
      "Epoch 20/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 4.9148 - accuracy: 0.0967\n",
      "Epoch 21/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 4.8758 - accuracy: 0.0973\n",
      "Epoch 22/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 4.8401 - accuracy: 0.0970\n",
      "Epoch 23/200\n",
      "11368/11368 [==============================] - 18s 2ms/step - loss: 4.8035 - accuracy: 0.1014\n",
      "Epoch 24/200\n",
      "11368/11368 [==============================] - 24s 2ms/step - loss: 4.7633 - accuracy: 0.1003\n",
      "Epoch 25/200\n",
      "11368/11368 [==============================] - 24s 2ms/step - loss: 4.7272 - accuracy: 0.1030\n",
      "Epoch 26/200\n",
      "11368/11368 [==============================] - 24s 2ms/step - loss: 4.6928 - accuracy: 0.1039\n",
      "Epoch 27/200\n",
      "11368/11368 [==============================] - 24s 2ms/step - loss: 4.6592 - accuracy: 0.1059\n",
      "Epoch 28/200\n",
      "11368/11368 [==============================] - 23s 2ms/step - loss: 4.6209 - accuracy: 0.1084\n",
      "Epoch 29/200\n",
      "11368/11368 [==============================] - 24s 2ms/step - loss: 4.5884 - accuracy: 0.1078\n",
      "Epoch 30/200\n",
      "11368/11368 [==============================] - 25s 2ms/step - loss: 4.5510 - accuracy: 0.1104\n",
      "Epoch 31/200\n",
      "11368/11368 [==============================] - 24s 2ms/step - loss: 4.5243 - accuracy: 0.1107\n",
      "Epoch 32/200\n",
      "11368/11368 [==============================] - 24s 2ms/step - loss: 4.4878 - accuracy: 0.1150\n",
      "Epoch 33/200\n",
      "11368/11368 [==============================] - 21s 2ms/step - loss: 4.4566 - accuracy: 0.1156\n",
      "Epoch 34/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 4.4310 - accuracy: 0.1137\n",
      "Epoch 35/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 4.4012 - accuracy: 0.1174\n",
      "Epoch 36/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 4.3763 - accuracy: 0.1212\n",
      "Epoch 37/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 4.3380 - accuracy: 0.1224\n",
      "Epoch 38/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 4.3141 - accuracy: 0.1229\n",
      "Epoch 39/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 4.2835 - accuracy: 0.1289\n",
      "Epoch 40/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 4.2591 - accuracy: 0.1252\n",
      "Epoch 41/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 4.2315 - accuracy: 0.1290\n",
      "Epoch 42/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 4.2040 - accuracy: 0.1294\n",
      "Epoch 43/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 4.3001 - accuracy: 0.1288\n",
      "Epoch 44/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 4.6331 - accuracy: 0.1127\n",
      "Epoch 45/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 4.4019 - accuracy: 0.1168\n",
      "Epoch 46/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 4.2821 - accuracy: 0.1279\n",
      "Epoch 47/200\n",
      "11368/11368 [==============================] - 14s 1ms/step - loss: 4.3951 - accuracy: 0.1166\n",
      "Epoch 48/200\n",
      "11368/11368 [==============================] - 14s 1ms/step - loss: 4.4715 - accuracy: 0.1084\n",
      "Epoch 49/200\n",
      "11368/11368 [==============================] - 14s 1ms/step - loss: 4.3277 - accuracy: 0.1195\n",
      "Epoch 50/200\n",
      "11368/11368 [==============================] - 14s 1ms/step - loss: 4.2524 - accuracy: 0.1201\n",
      "Epoch 51/200\n",
      "11368/11368 [==============================] - 14s 1ms/step - loss: 4.1897 - accuracy: 0.1273\n",
      "Epoch 52/200\n",
      "11368/11368 [==============================] - 15s 1ms/step - loss: 4.1423 - accuracy: 0.1320\n",
      "Epoch 53/200\n",
      "11368/11368 [==============================] - 14s 1ms/step - loss: 4.1021 - accuracy: 0.1326\n",
      "Epoch 54/200\n",
      "11368/11368 [==============================] - 16s 1ms/step - loss: 4.0616 - accuracy: 0.1344\n",
      "Epoch 55/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 4.0083 - accuracy: 0.1425\n",
      "Epoch 56/200\n",
      "11368/11368 [==============================] - 14s 1ms/step - loss: 3.9692 - accuracy: 0.1429 1s - loss: 3.949\n",
      "Epoch 57/200\n",
      "11368/11368 [==============================] - 15s 1ms/step - loss: 3.9269 - accuracy: 0.1495\n",
      "Epoch 58/200\n",
      "11368/11368 [==============================] - 15s 1ms/step - loss: 3.8747 - accuracy: 0.1532\n",
      "Epoch 59/200\n",
      "11368/11368 [==============================] - 14s 1ms/step - loss: 3.8298 - accuracy: 0.1580\n",
      "Epoch 60/200\n",
      "11368/11368 [==============================] - 14s 1ms/step - loss: 3.7852 - accuracy: 0.1611\n",
      "Epoch 61/200\n",
      "11368/11368 [==============================] - 14s 1ms/step - loss: 3.7382 - accuracy: 0.1639\n",
      "Epoch 62/200\n",
      "11368/11368 [==============================] - 14s 1ms/step - loss: 3.6877 - accuracy: 0.1752\n",
      "Epoch 63/200\n",
      "11368/11368 [==============================] - 14s 1ms/step - loss: 3.6384 - accuracy: 0.1778\n",
      "Epoch 64/200\n",
      "11368/11368 [==============================] - 14s 1ms/step - loss: 3.5895 - accuracy: 0.1829\n",
      "Epoch 65/200\n",
      "11368/11368 [==============================] - 14s 1ms/step - loss: 3.5335 - accuracy: 0.1902\n",
      "Epoch 66/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 3.4869 - accuracy: 0.1977\n",
      "Epoch 67/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 3.4482 - accuracy: 0.2027\n",
      "Epoch 68/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 3.3902 - accuracy: 0.2126\n",
      "Epoch 69/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 3.3392 - accuracy: 0.2205\n",
      "Epoch 70/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 3.2890 - accuracy: 0.2239\n",
      "Epoch 71/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 3.2334 - accuracy: 0.2339\n",
      "Epoch 72/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 3.1892 - accuracy: 0.2478\n",
      "Epoch 73/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 3.1352 - accuracy: 0.2571\n",
      "Epoch 74/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 3.0903 - accuracy: 0.2686\n",
      "Epoch 75/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 3.0388 - accuracy: 0.2716\n",
      "Epoch 76/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 2.9849 - accuracy: 0.2848\n",
      "Epoch 77/200\n",
      "11368/11368 [==============================] - 12s 1ms/step - loss: 2.9463 - accuracy: 0.2924\n",
      "Epoch 78/200\n",
      "11368/11368 [==============================] - 12s 1ms/step - loss: 2.8996 - accuracy: 0.3008\n",
      "Epoch 79/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 2.8415 - accuracy: 0.3168\n",
      "Epoch 80/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 2.7874 - accuracy: 0.3293\n",
      "Epoch 81/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 2.7460 - accuracy: 0.3352\n",
      "Epoch 82/200\n",
      "11368/11368 [==============================] - 13s 1ms/step - loss: 2.7022 - accuracy: 0.3481\n",
      "Epoch 83/200\n",
      "11368/11368 [==============================] - 11s 997us/step - loss: 2.6552 - accuracy: 0.3557\n",
      "Epoch 84/200\n",
      "11368/11368 [==============================] - 11s 1000us/step - loss: 2.6106 - accuracy: 0.3675\n",
      "Epoch 85/200\n",
      "11368/11368 [==============================] - 11s 995us/step - loss: 2.5503 - accuracy: 0.3838\n",
      "Epoch 86/200\n",
      "11368/11368 [==============================] - 11s 1000us/step - loss: 2.5236 - accuracy: 0.3833\n",
      "Epoch 87/200\n",
      "11368/11368 [==============================] - 11s 997us/step - loss: 2.4660 - accuracy: 0.3980\n",
      "Epoch 88/200\n",
      "11368/11368 [==============================] - 11s 992us/step - loss: 2.4267 - accuracy: 0.4097\n",
      "Epoch 89/200\n",
      "11368/11368 [==============================] - 11s 1000us/step - loss: 2.3920 - accuracy: 0.4164\n",
      "Epoch 90/200\n",
      "11368/11368 [==============================] - 11s 1ms/step - loss: 2.3463 - accuracy: 0.4293\n",
      "Epoch 91/200\n",
      "11368/11368 [==============================] - 11s 1ms/step - loss: 2.3030 - accuracy: 0.4363\n",
      "Epoch 92/200\n",
      "11368/11368 [==============================] - 11s 1ms/step - loss: 2.2640 - accuracy: 0.4460\n",
      "Epoch 93/200\n",
      "11368/11368 [==============================] - 11s 994us/step - loss: 2.2225 - accuracy: 0.4584\n",
      "Epoch 94/200\n",
      "11368/11368 [==============================] - 11s 1ms/step - loss: 2.1814 - accuracy: 0.4679\n",
      "Epoch 95/200\n",
      "11368/11368 [==============================] - 11s 998us/step - loss: 2.1443 - accuracy: 0.4734\n",
      "Epoch 96/200\n",
      "11368/11368 [==============================] - 11s 993us/step - loss: 2.1020 - accuracy: 0.4837\n",
      "Epoch 97/200\n",
      "11368/11368 [==============================] - 11s 995us/step - loss: 2.0681 - accuracy: 0.4948\n",
      "Epoch 98/200\n",
      "11368/11368 [==============================] - 11s 995us/step - loss: 2.0448 - accuracy: 0.5004\n",
      "Epoch 99/200\n",
      "11368/11368 [==============================] - 11s 996us/step - loss: 2.0078 - accuracy: 0.5027\n",
      "Epoch 100/200\n",
      "11368/11368 [==============================] - 12s 1ms/step - loss: 1.9610 - accuracy: 0.5154\n",
      "Epoch 101/200\n",
      "11368/11368 [==============================] - 11s 1ms/step - loss: 1.9221 - accuracy: 0.5282\n",
      "Epoch 102/200\n",
      "11368/11368 [==============================] - 11s 998us/step - loss: 1.8961 - accuracy: 0.5331\n",
      "Epoch 103/200\n",
      "11368/11368 [==============================] - 12s 1ms/step - loss: 1.8533 - accuracy: 0.5468\n",
      "Epoch 104/200\n",
      "11368/11368 [==============================] - 11s 1ms/step - loss: 1.8302 - accuracy: 0.5503\n",
      "Epoch 105/200\n",
      "11368/11368 [==============================] - 12s 1ms/step - loss: 1.7980 - accuracy: 0.5548\n",
      "Epoch 106/200\n",
      "11368/11368 [==============================] - 11s 1ms/step - loss: 1.7709 - accuracy: 0.5628\n",
      "Epoch 107/200\n",
      "11368/11368 [==============================] - 11s 1ms/step - loss: 1.7276 - accuracy: 0.5752\n",
      "Epoch 108/200\n",
      "11368/11368 [==============================] - 11s 1ms/step - loss: 1.6966 - accuracy: 0.5807\n",
      "Epoch 109/200\n",
      "11368/11368 [==============================] - 11s 997us/step - loss: 1.6697 - accuracy: 0.5874\n",
      "Epoch 110/200\n",
      "11368/11368 [==============================] - 11s 1000us/step - loss: 1.6388 - accuracy: 0.5954\n",
      "Epoch 111/200\n",
      "11368/11368 [==============================] - 11s 1ms/step - loss: 1.6186 - accuracy: 0.5958\n",
      "Epoch 112/200\n",
      "11368/11368 [==============================] - 11s 995us/step - loss: 1.5780 - accuracy: 0.6032\n",
      "Epoch 113/200\n",
      "11368/11368 [==============================] - 11s 1ms/step - loss: 1.5544 - accuracy: 0.6137\n",
      "Epoch 114/200\n",
      "11368/11368 [==============================] - 12s 1ms/step - loss: 1.5238 - accuracy: 0.6196\n",
      "Epoch 115/200\n",
      "11368/11368 [==============================] - 11s 1ms/step - loss: 1.5004 - accuracy: 0.6275\n",
      "Epoch 116/200\n",
      "11368/11368 [==============================] - 11s 997us/step - loss: 1.4724 - accuracy: 0.6293\n",
      "Epoch 117/200\n",
      "11368/11368 [==============================] - 11s 997us/step - loss: 1.4452 - accuracy: 0.6373\n",
      "Epoch 118/200\n",
      "11368/11368 [==============================] - 11s 992us/step - loss: 1.4131 - accuracy: 0.6469\n",
      "Epoch 119/200\n",
      "11368/11368 [==============================] - 11s 996us/step - loss: 1.3968 - accuracy: 0.6487\n",
      "Epoch 120/200\n",
      "11368/11368 [==============================] - 11s 995us/step - loss: 1.3757 - accuracy: 0.6557\n",
      "Epoch 121/200\n",
      "11368/11368 [==============================] - 12s 1ms/step - loss: 1.3499 - accuracy: 0.6610\n",
      "Epoch 122/200\n",
      "11368/11368 [==============================] - 12s 1ms/step - loss: 1.3200 - accuracy: 0.6692\n",
      "Epoch 123/200\n",
      "11368/11368 [==============================] - 11s 1ms/step - loss: 1.2939 - accuracy: 0.6724\n",
      "Epoch 124/200\n",
      "11368/11368 [==============================] - 11s 997us/step - loss: 1.2722 - accuracy: 0.6804\n",
      "Epoch 125/200\n",
      "11368/11368 [==============================] - 11s 1ms/step - loss: 1.2477 - accuracy: 0.6873\n",
      "Epoch 126/200\n",
      "11368/11368 [==============================] - 12s 1ms/step - loss: 1.2313 - accuracy: 0.6909\n",
      "Epoch 127/200\n",
      "11368/11368 [==============================] - 19s 2ms/step - loss: 1.1967 - accuracy: 0.7014\n",
      "Epoch 128/200\n",
      "11368/11368 [==============================] - 22s 2ms/step - loss: 1.1772 - accuracy: 0.7051\n",
      "Epoch 129/200\n",
      "11368/11368 [==============================] - 21s 2ms/step - loss: 1.1509 - accuracy: 0.7123\n",
      "Epoch 130/200\n",
      "11368/11368 [==============================] - 21s 2ms/step - loss: 1.1328 - accuracy: 0.7163\n",
      "Epoch 131/200\n",
      "11368/11368 [==============================] - 21s 2ms/step - loss: 1.1087 - accuracy: 0.7233\n",
      "Epoch 132/200\n",
      "11368/11368 [==============================] - 21s 2ms/step - loss: 1.0953 - accuracy: 0.7242\n",
      "Epoch 133/200\n",
      "11368/11368 [==============================] - 20s 2ms/step - loss: 1.0782 - accuracy: 0.7291\n",
      "Epoch 134/200\n",
      "11368/11368 [==============================] - 21s 2ms/step - loss: 1.0623 - accuracy: 0.7350\n",
      "Epoch 135/200\n",
      "11368/11368 [==============================] - 21s 2ms/step - loss: 1.0399 - accuracy: 0.7409\n",
      "Epoch 136/200\n",
      "11368/11368 [==============================] - ETA: 0s - loss: 1.0173 - accuracy: 0.74 - 20s 2ms/step - loss: 1.0178 - accuracy: 0.7489\n",
      "Epoch 137/200\n",
      "11368/11368 [==============================] - 21s 2ms/step - loss: 1.0015 - accuracy: 0.7478\n",
      "Epoch 138/200\n",
      "11368/11368 [==============================] - 21s 2ms/step - loss: 0.9860 - accuracy: 0.7573\n",
      "Epoch 139/200\n",
      "11368/11368 [==============================] - 20s 2ms/step - loss: 0.9858 - accuracy: 0.7586\n",
      "Epoch 140/200\n",
      "11368/11368 [==============================] - 20s 2ms/step - loss: 0.9486 - accuracy: 0.7650\n",
      "Epoch 141/200\n",
      "11368/11368 [==============================] - 21s 2ms/step - loss: 0.9215 - accuracy: 0.7733\n",
      "Epoch 142/200\n",
      "11368/11368 [==============================] - 21s 2ms/step - loss: 0.9072 - accuracy: 0.7781\n",
      "Epoch 143/200\n",
      "11368/11368 [==============================] - 21s 2ms/step - loss: 0.8920 - accuracy: 0.7807\n",
      "Epoch 144/200\n",
      "11368/11368 [==============================] - 21s 2ms/step - loss: 0.8682 - accuracy: 0.7899\n",
      "Epoch 145/200\n",
      "11368/11368 [==============================] - 21s 2ms/step - loss: 0.8475 - accuracy: 0.7906\n",
      "Epoch 146/200\n",
      "11368/11368 [==============================] - 21s 2ms/step - loss: 0.8306 - accuracy: 0.8018\n",
      "Epoch 147/200\n",
      "11368/11368 [==============================] - 20s 2ms/step - loss: 0.8127 - accuracy: 0.8050\n",
      "Epoch 148/200\n",
      "11368/11368 [==============================] - 21s 2ms/step - loss: 0.7987 - accuracy: 0.8052\n",
      "Epoch 149/200\n",
      "11368/11368 [==============================] - 21s 2ms/step - loss: 0.7853 - accuracy: 0.8145\n",
      "Epoch 150/200\n",
      "11368/11368 [==============================] - 21s 2ms/step - loss: 0.7713 - accuracy: 0.8125\n",
      "Epoch 151/200\n",
      "11368/11368 [==============================] - 21s 2ms/step - loss: 0.7630 - accuracy: 0.8171\n",
      "Epoch 152/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11368/11368 [==============================] - 22s 2ms/step - loss: 0.7412 - accuracy: 0.8210\n",
      "Epoch 153/200\n",
      "11368/11368 [==============================] - 21s 2ms/step - loss: 0.7246 - accuracy: 0.8280\n",
      "Epoch 154/200\n",
      "11368/11368 [==============================] - 20s 2ms/step - loss: 0.7112 - accuracy: 0.8301\n",
      "Epoch 155/200\n",
      "11368/11368 [==============================] - 21s 2ms/step - loss: 0.6841 - accuracy: 0.8396\n",
      "Epoch 156/200\n",
      "11368/11368 [==============================] - 20s 2ms/step - loss: 0.6623 - accuracy: 0.8451\n",
      "Epoch 157/200\n",
      "11368/11368 [==============================] - 21s 2ms/step - loss: 0.6575 - accuracy: 0.8472\n",
      "Epoch 158/200\n",
      "11368/11368 [==============================] - 20s 2ms/step - loss: 0.6452 - accuracy: 0.8495\n",
      "Epoch 159/200\n",
      "11368/11368 [==============================] - 20s 2ms/step - loss: 0.6325 - accuracy: 0.8555\n",
      "Epoch 160/200\n",
      "11368/11368 [==============================] - 21s 2ms/step - loss: 0.6169 - accuracy: 0.8573\n",
      "Epoch 161/200\n",
      "11368/11368 [==============================] - 21s 2ms/step - loss: 0.6110 - accuracy: 0.8582\n",
      "Epoch 162/200\n",
      "11368/11368 [==============================] - 20s 2ms/step - loss: 0.5870 - accuracy: 0.8661\n",
      "Epoch 163/200\n",
      "11368/11368 [==============================] - 21s 2ms/step - loss: 0.5740 - accuracy: 0.8695\n",
      "Epoch 164/200\n",
      "11368/11368 [==============================] - 20s 2ms/step - loss: 0.5563 - accuracy: 0.8734\n",
      "Epoch 165/200\n",
      "11368/11368 [==============================] - 21s 2ms/step - loss: 0.5445 - accuracy: 0.8768\n",
      "Epoch 166/200\n",
      "11368/11368 [==============================] - 21s 2ms/step - loss: 0.5385 - accuracy: 0.8770\n",
      "Epoch 167/200\n",
      "11368/11368 [==============================] - 22s 2ms/step - loss: 0.5300 - accuracy: 0.8791\n",
      "Epoch 168/200\n",
      "11368/11368 [==============================] - 21s 2ms/step - loss: 0.5239 - accuracy: 0.8820\n",
      "Epoch 169/200\n",
      "11368/11368 [==============================] - 21s 2ms/step - loss: 0.4987 - accuracy: 0.8917\n",
      "Epoch 170/200\n",
      "11368/11368 [==============================] - 22s 2ms/step - loss: 0.4828 - accuracy: 0.8946\n",
      "Epoch 171/200\n",
      "11368/11368 [==============================] - 22s 2ms/step - loss: 0.4698 - accuracy: 0.8968\n",
      "Epoch 172/200\n",
      "11368/11368 [==============================] - 23s 2ms/step - loss: 0.4622 - accuracy: 0.8965\n",
      "Epoch 173/200\n",
      "11368/11368 [==============================] - 23s 2ms/step - loss: 0.4541 - accuracy: 0.9010\n",
      "Epoch 174/200\n",
      "11368/11368 [==============================] - 23s 2ms/step - loss: 0.4444 - accuracy: 0.9014\n",
      "Epoch 175/200\n",
      "11368/11368 [==============================] - 23s 2ms/step - loss: 0.4440 - accuracy: 0.9029\n",
      "Epoch 176/200\n",
      "11368/11368 [==============================] - 22s 2ms/step - loss: 0.4450 - accuracy: 0.9020\n",
      "Epoch 177/200\n",
      "11368/11368 [==============================] - 23s 2ms/step - loss: 0.4310 - accuracy: 0.9067\n",
      "Epoch 178/200\n",
      "11368/11368 [==============================] - 22s 2ms/step - loss: 0.4067 - accuracy: 0.9139\n",
      "Epoch 179/200\n",
      "11368/11368 [==============================] - 22s 2ms/step - loss: 0.3921 - accuracy: 0.9171\n",
      "Epoch 180/200\n",
      "11368/11368 [==============================] - 22s 2ms/step - loss: 0.3799 - accuracy: 0.9207\n",
      "Epoch 181/200\n",
      "11368/11368 [==============================] - 22s 2ms/step - loss: 0.3590 - accuracy: 0.9277\n",
      "Epoch 182/200\n",
      "11368/11368 [==============================] - 22s 2ms/step - loss: 0.3528 - accuracy: 0.9285\n",
      "Epoch 183/200\n",
      "11368/11368 [==============================] - 22s 2ms/step - loss: 0.3473 - accuracy: 0.9306\n",
      "Epoch 184/200\n",
      "11368/11368 [==============================] - 22s 2ms/step - loss: 0.3310 - accuracy: 0.9334\n",
      "Epoch 185/200\n",
      "11368/11368 [==============================] - 22s 2ms/step - loss: 0.3337 - accuracy: 0.9327\n",
      "Epoch 186/200\n",
      "11368/11368 [==============================] - 22s 2ms/step - loss: 0.3282 - accuracy: 0.9323\n",
      "Epoch 187/200\n",
      "11368/11368 [==============================] - 22s 2ms/step - loss: 0.3093 - accuracy: 0.9404\n",
      "Epoch 188/200\n",
      "11368/11368 [==============================] - 22s 2ms/step - loss: 0.3284 - accuracy: 0.9331\n",
      "Epoch 189/200\n",
      "11368/11368 [==============================] - 22s 2ms/step - loss: 0.3043 - accuracy: 0.9391\n",
      "Epoch 190/200\n",
      "11368/11368 [==============================] - 22s 2ms/step - loss: 0.2943 - accuracy: 0.9423\n",
      "Epoch 191/200\n",
      "11368/11368 [==============================] - 22s 2ms/step - loss: 0.3148 - accuracy: 0.9333\n",
      "Epoch 192/200\n",
      "11368/11368 [==============================] - 22s 2ms/step - loss: 0.3062 - accuracy: 0.9360\n",
      "Epoch 193/200\n",
      "11368/11368 [==============================] - 22s 2ms/step - loss: 0.2718 - accuracy: 0.9476\n",
      "Epoch 194/200\n",
      "11368/11368 [==============================] - 22s 2ms/step - loss: 0.2528 - accuracy: 0.9527\n",
      "Epoch 195/200\n",
      "11368/11368 [==============================] - 22s 2ms/step - loss: 0.2259 - accuracy: 0.9623\n",
      "Epoch 196/200\n",
      "11368/11368 [==============================] - 22s 2ms/step - loss: 0.2139 - accuracy: 0.9641\n",
      "Epoch 197/200\n",
      "11368/11368 [==============================] - 23s 2ms/step - loss: 0.2136 - accuracy: 0.9634\n",
      "Epoch 198/200\n",
      "11368/11368 [==============================] - 23s 2ms/step - loss: 0.1978 - accuracy: 0.9685\n",
      "Epoch 199/200\n",
      "11368/11368 [==============================] - 23s 2ms/step - loss: 0.1935 - accuracy: 0.9685\n",
      "Epoch 200/200\n",
      "11368/11368 [==============================] - 22s 2ms/step - loss: 0.1953 - accuracy: 0.9654\n",
      "Wall time: 54min 49s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x15e87cf5188>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X, y, batch_size=128, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d822fdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('LM_moby_dick.h5') saved once immediately after training, commented to avoid accidental overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0736d662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump(tokenizer, open('LM_simpletokenizer', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a1e5ed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "861e6aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
    "    output_text = []\n",
    "    \n",
    "    input_text = seed_text\n",
    "    \n",
    "    for i in range(num_gen_words):\n",
    "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
    "        pred_word_ind = model.predict_classes(pad_encoded, verbose=0)[0]\n",
    "        pred_word = tokenizer.index_word[pred_word_ind]\n",
    "        input_text += ' ' + pred_word\n",
    "        output_text.append(pred_word)\n",
    "    \n",
    "    return ' '.join(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e723dc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('LM_moby_dick.h5')\n",
    "tokenizer = load(open('LM_simpletokenizer', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "53371831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['call',\n",
       " 'me',\n",
       " 'ishmael',\n",
       " 'some',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'never',\n",
       " 'mind',\n",
       " 'how',\n",
       " 'long',\n",
       " 'precisely',\n",
       " 'having',\n",
       " 'little',\n",
       " 'or',\n",
       " 'no',\n",
       " 'money',\n",
       " 'in',\n",
       " 'my',\n",
       " 'purse',\n",
       " 'and',\n",
       " 'nothing',\n",
       " 'particular',\n",
       " 'to',\n",
       " 'interest',\n",
       " 'me',\n",
       " 'on']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a37df0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(101)\n",
    "random_pick = random.randint(0, len(text_sequences))\n",
    "random_seed_text = text_sequences[random_pick]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "94523a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and',\n",
       " 'throwing',\n",
       " 'the',\n",
       " 'clothes',\n",
       " 'to',\n",
       " 'one',\n",
       " 'side',\n",
       " 'he',\n",
       " 'really',\n",
       " 'did',\n",
       " 'this',\n",
       " 'in',\n",
       " 'not',\n",
       " 'only',\n",
       " 'a',\n",
       " 'civil',\n",
       " 'but',\n",
       " 'a',\n",
       " 'really',\n",
       " 'kind',\n",
       " 'and',\n",
       " 'charitable',\n",
       " 'way',\n",
       " 'i',\n",
       " 'stood',\n",
       " 'looking']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "750647f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = ' '.join(random_seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1bfe7b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and throwing the clothes to one side he really did this in not only a civil but a really kind and charitable way i stood looking'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fd1ac047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"at him a moment for all his tattooings he was on the whole a clean comely looking cannibal what 's all this fuss i have\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, seq_len, seed_text, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "24d932b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = load_model('epochBIG.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2be33dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer2 = load(open('epochBIG','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6a03ace2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"at that stubb ' my frame roman eyes of his own power for the whale 's grain to wrenched progeny for a fever drawn up\""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model2, tokenizer2, seq_len, seed_text, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e9e620",
   "metadata": {},
   "source": [
    "### Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9e8e1780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f28686d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_qa.txt', 'rb') as f:\n",
    "    train_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f2d5dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_qa.txt', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d11e69bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "aa96185a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fe3244a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0] #story, question, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9abc9a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "47b1533e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "57ae241e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f9bc5a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "53f4c64e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'journeyed',\n",
       " 'moved',\n",
       " 'the',\n",
       " 'to'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6bc8ab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "\n",
    "for story, question, answer in all_data:\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1a0d13b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add(\"no\")\n",
    "vocab.add(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "abd2e336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ea670b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6f51ee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_story_lens = [len(data[0]) for data in all_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5e3f4e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len = max(all_story_lens)\n",
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4221027e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])\n",
    "max_question_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f64b1580",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8383c3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 1,\n",
       " 'to': 2,\n",
       " 'bedroom': 3,\n",
       " 'football': 4,\n",
       " 'no': 5,\n",
       " 'apple': 6,\n",
       " 'kitchen': 7,\n",
       " 'garden': 8,\n",
       " 'moved': 9,\n",
       " 'got': 10,\n",
       " 'office': 11,\n",
       " 'there': 12,\n",
       " 'milk': 13,\n",
       " 'left': 14,\n",
       " 'the': 15,\n",
       " 'bathroom': 16,\n",
       " 'took': 17,\n",
       " 'is': 18,\n",
       " 'went': 19,\n",
       " 'grabbed': 20,\n",
       " 'dropped': 21,\n",
       " 'travelled': 22,\n",
       " 'down': 23,\n",
       " 'john': 24,\n",
       " 'yes': 25,\n",
       " 'back': 26,\n",
       " 'picked': 27,\n",
       " 'discarded': 28,\n",
       " 'mary': 29,\n",
       " 'sandra': 30,\n",
       " 'put': 31,\n",
       " 'journeyed': 32,\n",
       " 'hallway': 33,\n",
       " 'daniel': 34,\n",
       " 'in': 35,\n",
       " 'up': 36,\n",
       " '?': 37}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0acc6f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []\n",
    "\n",
    "for story, question, answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)\n",
    "    train_answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "557071f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.',\n",
       "  'Mary',\n",
       "  'went',\n",
       "  'back',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.',\n",
       "  'Daniel',\n",
       "  'went',\n",
       "  'back',\n",
       "  'to',\n",
       "  'the',\n",
       "  'hallway',\n",
       "  '.'],\n",
       " ['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.',\n",
       "  'Mary',\n",
       "  'went',\n",
       "  'back',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.',\n",
       "  'Daniel',\n",
       "  'went',\n",
       "  'back',\n",
       "  'to',\n",
       "  'the',\n",
       "  'hallway',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'went',\n",
       "  'to',\n",
       "  'the',\n",
       "  'kitchen',\n",
       "  '.',\n",
       "  'Daniel',\n",
       "  'went',\n",
       "  'back',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.']]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_story_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "94ff0e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1ec3f70c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[29, 9, 2, 15, 16, 1, 30, 32, 2, 15, 3, 1],\n",
       " [29,\n",
       "  9,\n",
       "  2,\n",
       "  15,\n",
       "  16,\n",
       "  1,\n",
       "  30,\n",
       "  32,\n",
       "  2,\n",
       "  15,\n",
       "  3,\n",
       "  1,\n",
       "  29,\n",
       "  19,\n",
       "  26,\n",
       "  2,\n",
       "  15,\n",
       "  3,\n",
       "  1,\n",
       "  34,\n",
       "  19,\n",
       "  26,\n",
       "  2,\n",
       "  15,\n",
       "  33,\n",
       "  1],\n",
       " [29,\n",
       "  9,\n",
       "  2,\n",
       "  15,\n",
       "  16,\n",
       "  1,\n",
       "  30,\n",
       "  32,\n",
       "  2,\n",
       "  15,\n",
       "  3,\n",
       "  1,\n",
       "  29,\n",
       "  19,\n",
       "  26,\n",
       "  2,\n",
       "  15,\n",
       "  3,\n",
       "  1,\n",
       "  34,\n",
       "  19,\n",
       "  26,\n",
       "  2,\n",
       "  15,\n",
       "  33,\n",
       "  1,\n",
       "  30,\n",
       "  19,\n",
       "  2,\n",
       "  15,\n",
       "  7,\n",
       "  1,\n",
       "  34,\n",
       "  19,\n",
       "  26,\n",
       "  2,\n",
       "  15,\n",
       "  16,\n",
       "  1]]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_story_seq[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ec6eb3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index = tokenizer.word_index, \n",
    "                      max_story_len=max_story_len, max_question_len=max_question_len):\n",
    "    X = []\n",
    "    Xq = []\n",
    "    Y = []\n",
    "    \n",
    "    for story, question, answer in data:\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        xq = [word_index[word.lower()] for word in question]\n",
    "        \n",
    "        y = np.zeros(len(word_index) + 1)\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "    \n",
    "    return (pad_sequences(X, maxlen=max_story_len), pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8c2155e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, questions_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0d0b4146",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, questions_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6055246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout, add, dot, concatenate, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "88a14fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8159b827",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8451adab",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size, output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9bf19485",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size, output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cf4fc645",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size, output_dim=64, input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f4e5ab21",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "70d21696",
   "metadata": {},
   "outputs": [],
   "source": [
    "match = dot([input_encoded_m, question_encoded], axes=(2,2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e1eaa693",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = add([match, input_encoded_c])\n",
    "response = Permute((2,1))(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "42c84208",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "018db7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(?, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "85b5c8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = LSTM(32)(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7e70da9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "99434f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Activation('softmax')(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "02d806a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([input_sequence, question], answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "cd55400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0ac303f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       multiple             2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_5 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 156, 6)       0           sequential_3[1][0]               \n",
      "                                                                 sequential_5[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)       multiple             228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
      "                                                                 sequential_4[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
      "                                                                 sequential_5[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 38)           1254        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 38)           0           dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "99a92bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "10000/10000 [==============================] - 6s 566us/step - loss: 0.6953 - accuracy: 0.4995 - val_loss: 0.6937 - val_accuracy: 0.5030\n",
      "Epoch 2/30\n",
      "10000/10000 [==============================] - 6s 569us/step - loss: 0.6950 - accuracy: 0.5042 - val_loss: 0.6933 - val_accuracy: 0.4860\n",
      "Epoch 3/30\n",
      "10000/10000 [==============================] - 6s 569us/step - loss: 0.6950 - accuracy: 0.4929 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
      "Epoch 4/30\n",
      "10000/10000 [==============================] - 6s 582us/step - loss: 0.6943 - accuracy: 0.4993 - val_loss: 0.6944 - val_accuracy: 0.4970\n",
      "Epoch 5/30\n",
      "10000/10000 [==============================] - 6s 602us/step - loss: 0.6940 - accuracy: 0.5071 - val_loss: 0.6941 - val_accuracy: 0.5110\n",
      "Epoch 6/30\n",
      "10000/10000 [==============================] - 6s 575us/step - loss: 0.6931 - accuracy: 0.5099 - val_loss: 0.6937 - val_accuracy: 0.5420\n",
      "Epoch 7/30\n",
      "10000/10000 [==============================] - 7s 660us/step - loss: 0.6872 - accuracy: 0.5401 - val_loss: 0.6805 - val_accuracy: 0.5450\n",
      "Epoch 8/30\n",
      "10000/10000 [==============================] - 7s 734us/step - loss: 0.6673 - accuracy: 0.5839 - val_loss: 0.6505 - val_accuracy: 0.6100\n",
      "Epoch 9/30\n",
      "10000/10000 [==============================] - 6s 627us/step - loss: 0.6387 - accuracy: 0.6415 - val_loss: 0.5930 - val_accuracy: 0.6910\n",
      "Epoch 10/30\n",
      "10000/10000 [==============================] - 6s 644us/step - loss: 0.5830 - accuracy: 0.7062 - val_loss: 0.5279 - val_accuracy: 0.7480\n",
      "Epoch 11/30\n",
      "10000/10000 [==============================] - 6s 614us/step - loss: 0.5437 - accuracy: 0.7353 - val_loss: 0.4829 - val_accuracy: 0.7730\n",
      "Epoch 12/30\n",
      "10000/10000 [==============================] - 7s 664us/step - loss: 0.4993 - accuracy: 0.7651 - val_loss: 0.4487 - val_accuracy: 0.8080\n",
      "Epoch 13/30\n",
      "10000/10000 [==============================] - 7s 664us/step - loss: 0.4776 - accuracy: 0.7785 - val_loss: 0.4343 - val_accuracy: 0.7900\n",
      "Epoch 14/30\n",
      "10000/10000 [==============================] - 7s 650us/step - loss: 0.4559 - accuracy: 0.7880 - val_loss: 0.4302 - val_accuracy: 0.7980\n",
      "Epoch 15/30\n",
      "10000/10000 [==============================] - 8s 760us/step - loss: 0.4378 - accuracy: 0.7958 - val_loss: 0.4116 - val_accuracy: 0.8070\n",
      "Epoch 16/30\n",
      "10000/10000 [==============================] - 7s 720us/step - loss: 0.4286 - accuracy: 0.7962 - val_loss: 0.4068 - val_accuracy: 0.8080\n",
      "Epoch 17/30\n",
      "10000/10000 [==============================] - 7s 680us/step - loss: 0.4139 - accuracy: 0.8126 - val_loss: 0.3947 - val_accuracy: 0.8110\n",
      "Epoch 18/30\n",
      "10000/10000 [==============================] - 7s 670us/step - loss: 0.4021 - accuracy: 0.8173 - val_loss: 0.4008 - val_accuracy: 0.8170\n",
      "Epoch 19/30\n",
      "10000/10000 [==============================] - 7s 675us/step - loss: 0.3917 - accuracy: 0.8259 - val_loss: 0.3845 - val_accuracy: 0.8140\n",
      "Epoch 20/30\n",
      "10000/10000 [==============================] - 7s 677us/step - loss: 0.3865 - accuracy: 0.8240 - val_loss: 0.3825 - val_accuracy: 0.8190\n",
      "Epoch 21/30\n",
      "10000/10000 [==============================] - 7s 718us/step - loss: 0.3779 - accuracy: 0.8289 - val_loss: 0.3873 - val_accuracy: 0.8200\n",
      "Epoch 22/30\n",
      "10000/10000 [==============================] - 7s 704us/step - loss: 0.3696 - accuracy: 0.8362 - val_loss: 0.3951 - val_accuracy: 0.8210\n",
      "Epoch 23/30\n",
      "10000/10000 [==============================] - 7s 682us/step - loss: 0.3660 - accuracy: 0.8353 - val_loss: 0.3738 - val_accuracy: 0.8250\n",
      "Epoch 24/30\n",
      "10000/10000 [==============================] - 7s 682us/step - loss: 0.3563 - accuracy: 0.8407 - val_loss: 0.3638 - val_accuracy: 0.8300\n",
      "Epoch 25/30\n",
      "10000/10000 [==============================] - 7s 692us/step - loss: 0.3567 - accuracy: 0.8386 - val_loss: 0.3750 - val_accuracy: 0.8130\n",
      "Epoch 26/30\n",
      "10000/10000 [==============================] - 7s 715us/step - loss: 0.3496 - accuracy: 0.8406 - val_loss: 0.3650 - val_accuracy: 0.8250\n",
      "Epoch 27/30\n",
      "10000/10000 [==============================] - 7s 681us/step - loss: 0.3522 - accuracy: 0.8426 - val_loss: 0.3684 - val_accuracy: 0.8250\n",
      "Epoch 28/30\n",
      "10000/10000 [==============================] - 7s 689us/step - loss: 0.3435 - accuracy: 0.8480 - val_loss: 0.3589 - val_accuracy: 0.8360\n",
      "Epoch 29/30\n",
      "10000/10000 [==============================] - 7s 694us/step - loss: 0.3458 - accuracy: 0.8480 - val_loss: 0.3577 - val_accuracy: 0.8310\n",
      "Epoch 30/30\n",
      "10000/10000 [==============================] - 7s 734us/step - loss: 0.3399 - accuracy: 0.8485 - val_loss: 0.3589 - val_accuracy: 0.8270\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([inputs_train, questions_train], answers_train, batch_size=32, epochs=30, \\\n",
    "                    validation_data=([inputs_test, questions_test], answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e67c301e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "00a722b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([inputs_test, questions_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "33748137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n",
      "0.99936813\n"
     ]
    }
   ],
   "source": [
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(k)\n",
    "print(pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "098e444d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b38c8791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(story_text, question_text, correct_answer):\n",
    "    data = [(story_text.split(), question_text.split(), correct_answer)]\n",
    "    story_vec, question_vec, answer_vec = vectorize_stories(data)\n",
    "    pred_results = model.predict(([story_vec, question_vec]))\n",
    "    pred_answer_index = np.argmax(pred_results[0])\n",
    "    \n",
    "    if pred_answer_index == 5:\n",
    "        pred_answer = 'no'\n",
    "    elif pred_answer_index == 25:\n",
    "        pred_answer = 'yes'\n",
    "    else:\n",
    "        pred_answer = \"neither yes nor no, so you've got a problem\"\n",
    "    \n",
    "    print(f\"The predicted answer is {pred_answer} with {round(pred_results[0][pred_answer_index]*100, ndigits=2)}% confidence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a3f75c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted answer is yes with 89.22% confidence.\n"
     ]
    }
   ],
   "source": [
    "ask_question(\"John left the kitchen . Sandra dropped the football in the garden .\", \n",
    "             \"Is the football in the garden ?\", \"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ec3ece1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted answer is yes with 56.38% confidence.\n"
     ]
    }
   ],
   "source": [
    "ask_question(\"John put the milk in the office . The apple got discarded in the hallway .\",\n",
    "             \"Is the milk in the hallway ?\", \"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40133d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_course",
   "language": "python",
   "name": "nlp_course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
